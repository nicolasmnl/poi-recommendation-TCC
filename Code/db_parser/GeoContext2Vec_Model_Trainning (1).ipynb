{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD4OywR1-4Yl"
   },
   "source": [
    "# Instalação de dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: binary in ./anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Collecting gensim==3.6.0\n",
      "  Using cached gensim-3.6.0-cp38-cp38-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.7.2)\n",
      "Requirement already satisfied: six>=1.5.0 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (5.1.0)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install binary gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "#!pip3 uninstall gensim -y\n",
    "! pip3 uninstall numpy -y    \n",
    "#!apt-get install python3-dev build-essential      \n",
    "#!pip3 install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.23.4 which is incompatible.\n",
      "tensorflow-gpu 2.9.1 requires absl-py>=1.0.0, but you have absl-py 0.15.0 which is incompatible.\n",
      "sentence-transformers 2.2.2 requires transformers<5.0.0,>=4.6.0, but you have transformers 3.0.2 which is incompatible.\n",
      "scipy 1.7.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.4 which is incompatible.\n",
      "ktrain 0.28.2 requires scikit-learn==0.23.2, but you have scikit-learn 1.1.1 which is incompatible.\n",
      "ktrain 0.28.2 requires transformers<=4.10.3,>=4.0.0, but you have transformers 3.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.4\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2yAvehq-xHt",
    "outputId": "cba11b91-b499-459f-fe23-5d68b60ac674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.6.0\n",
      "  Using cached gensim-3.6.0-cp38-cp38-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.7.2)\n",
      "Requirement already satisfied: six>=1.5.0 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in ./anaconda3/lib/python3.8/site-packages (from gensim==3.6.0) (5.1.0)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.1.2\n",
      "    Uninstalling gensim-4.1.2:\n",
      "      Successfully uninstalled gensim-4.1.2\n",
      "Successfully installed gensim-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim==3.6.0\n",
    "#!pip install gensim==3.7.1\n",
    "#!pip install gensim==4.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_F1MrhcZ-7Zu"
   },
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XeMfHRaC_BMP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_826500/1128966852.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from time import time  # To time our operations\n",
    "\n",
    "#import logging  # Setting up the loggings to monitor gensim\n",
    "#logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-06Q-iwFwZ9z"
   },
   "source": [
    "## Treinamento em Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgjzxY-bxEMK",
    "outputId": "c2e4e84b-6f51-4ec1-e65c-86de1087140f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model (tuple of weight): 0.7\n",
      "loading file: ./geographic/train_files/new-york-sl-tuple-geoc2vec-pois_polygons_information-pfp-c.csv\n",
      "saving file: ./geographic/model/new-york-sl-tuple-geoc2vec-pois_polygons_informationpfp-c.model\n",
      "Training model (tuple of weight): 0.7\n",
      "loading file: ./geographic/train_files/new-york-sl-tuple-geoc2vec-pois_roads_information-pfp-c.csv\n",
      "saving file: ./geographic/model/new-york-sl-tuple-geoc2vec-pois_roads_informationpfp-c.model\n",
      "Training model (tuple of weight): 0.7\n",
      "loading file: ./geographic/train_files/new-york-sl-tuple-geoc2vec-pois_lines_information-pfp-c.csv\n",
      "saving file: ./geographic/model/new-york-sl-tuple-geoc2vec-pois_lines_informationpfp-c.model\n",
      "Training model (tuple of weight): 0.7\n",
      "loading file: ./geographic/train_files/new-york-sl-tuple-geoc2vec-pois_points_information-pfp-c.csv\n",
      "saving file: ./geographic/model/new-york-sl-tuple-geoc2vec-pois_points_informationpfp-c.model\n",
      "Time to train the model: 0.01 mins\n",
      "Process finish.\n"
     ]
    }
   ],
   "source": [
    "# Configurando variáveis de controle e inspeção\n",
    "\n",
    "cores = multiprocessing.cpu_count()   #Quantidade de cores utilizados no treinamento\n",
    "\n",
    "t = time()  #Tempo de realização do processo\n",
    "\n",
    "osm_tables = ['pois_polygons_information', 'pois_roads_information', 'pois_lines_information', 'pois_points_information']\n",
    "# osm_tables = ['pois_polygons_information']\n",
    "#osm_tables = ['bins_roads_information', 'bins_lines_information']\n",
    "#osm_tables = ['bins_polygons_information']\n",
    "\n",
    "for osm_table in osm_tables:\n",
    "    n = 400\n",
    "    w = 0.7\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Training model (tuple of weight):', w)\n",
    "\n",
    "    #ARQUIVO DE DADOS\n",
    "    file_name = './geographic/train_files/new-york-sl-tuple-geoc2vec-' + osm_table+ '-pfp-c.csv'\n",
    "\n",
    "    print(\"loading file:\", file_name)\n",
    "    tuples = pd.read_csv(file_name)\n",
    "\n",
    "    #Removendo linhas danificadas\n",
    "    tuples = tuples.dropna()\n",
    "    tuples = tuples[['center_poi', 'context_osm']]\n",
    "\n",
    "\n",
    "    #Adaptando para sentenças do word2vec\n",
    "    sentencesTuples = tuples.values.tolist()\n",
    "\n",
    "    #Criando estrutura do skip-gram\n",
    "    p2v_modeltp = Word2Vec(min_count=1,\n",
    "                            window=1,\n",
    "                            sg=1, #Skip-gram\n",
    "                            vector_size=35, #TAMANHO DO VETOR\n",
    "                            sample=6e-5, \n",
    "                            alpha=0.03, \n",
    "                            min_alpha=0.0007, \n",
    "                            negative=20,\n",
    "                            workers=cores-1)\n",
    "\n",
    "\n",
    "    #Criando vocubulário\n",
    "    p2v_modeltp.build_vocab(sentencesTuples, progress_per=10000)\n",
    "\n",
    "\n",
    "    #Treinando o modelo\n",
    "    p2v_modeltp.train(sentencesTuples, total_examples=p2v_modeltp.corpus_count, epochs=1, report_delay=1)\n",
    "\n",
    "    #Salvando em arquivo\n",
    "    model_name = './geographic/model/new-york-sl-tuple-geoc2vec-' + osm_table+ 'pfp-c.model'\n",
    "    \n",
    "    print('saving file:', model_name)\n",
    "    p2v_modeltp.save(model_name)\n",
    "\n",
    "\n",
    "        #except Exception as e:\n",
    "            #print(str(e))\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))        \n",
    "print('Process finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('points_historic_house', 0.5979353189468384),\n",
       " ('points_barrier_bollard', 0.5952308773994446),\n",
       " ('points_leisure_fitness_centre', 0.5438188910484314),\n",
       " ('Ice Cream Shop', 0.5426251292228699),\n",
       " ('points_amenity_post_office', 0.5368043184280396),\n",
       " ('Garden', 0.5327520966529846),\n",
       " ('Clothing Store', 0.5298491716384888),\n",
       " ('Drugstore / Pharmacy', 0.5279991030693054),\n",
       " ('points_highway_elevator', 0.5232389569282532),\n",
       " ('College Academic Building', 0.5219079256057739)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2v_modeltp.wv.most_similar(positive=['Burger Joint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bar', 0.8342798352241516),\n",
       " ('points_amenity_bicycle_parking', 0.8123246431350708),\n",
       " ('points_covered_no', 0.8061373829841614),\n",
       " ('points_barrier_bollard', 0.8020102977752686),\n",
       " ('points_highway_crossing', 0.756341278553009),\n",
       " ('Coffee Shop', 0.7543727159500122),\n",
       " ('points_amenity_charging_station', 0.7541670203208923),\n",
       " ('points_barrier_kerb', 0.7423862218856812),\n",
       " ('American Restaurant', 0.7271029949188232),\n",
       " ('Bowling Alley', 0.7263635396957397)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2v_modeltp.wv.most_similar(positive=['Park'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('points_barrier_bollard', 0.7203967571258545),\n",
       " ('American Restaurant', 0.7024220824241638),\n",
       " ('Residential Building (Apartment / Condo)', 0.6553056836128235),\n",
       " ('points_highway_crossing', 0.6469929814338684),\n",
       " ('Airport', 0.6395797729492188),\n",
       " ('points_covered_no', 0.6297082901000977),\n",
       " ('Korean Restaurant', 0.6239877343177795),\n",
       " ('points_amenity_bench', 0.6144056916236877),\n",
       " ('Home (private)', 0.6076717376708984),\n",
       " ('Bank', 0.6037388443946838)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2v_modeltp.wv.most_similar(positive=['Ice Cream Shop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polygons_building_stable', 0.6235930323600769),\n",
       " ('polygons_natural_rock', 0.41226842999458313),\n",
       " ('polygons_building_food_and_drink', 0.3605819642543793),\n",
       " ('Tanning Salon', 0.33694538474082947),\n",
       " ('polygons_sport_pilates', 0.31601762771606445),\n",
       " ('polygons_surface_acrylic', 0.29497602581977844),\n",
       " ('polygons_natural_shingle', 0.29106175899505615),\n",
       " ('polygons_surface_mondotrack', 0.2867780327796936),\n",
       " ('polygons_leisure_recreation_ground', 0.27139949798583984),\n",
       " ('polygons_sport_american_football;soccer;baseball', 0.26619940996170044)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2v_modeltp.wv.most_similar(negative=['Ice Cream Shop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './geographic/GEOC2VEC/new-york-sl-tuple-geoc2vec5bin-wgt0.5pfp-concat-c.model'\n",
    "p2v_modeltp = Word2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xHloq6HRom6U",
    "AzIzOXRdn10p"
   ],
   "name": "Place2Vec  - Model Trainning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
