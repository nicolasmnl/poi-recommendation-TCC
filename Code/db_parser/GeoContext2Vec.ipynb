{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /home/salatiel/anaconda3/envs/tcc/lib/python3.10/site-packages (2.9.9)\n"
     ]
    }
   ],
   "source": [
    "! pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: gensim==3.6.0 in /home/salatiel/anaconda3/lib/python3.7/site-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/salatiel/anaconda3/lib/python3.7/site-packages (from gensim==3.6.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/salatiel/anaconda3/lib/python3.7/site-packages (from gensim==3.6.0) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /home/salatiel/anaconda3/lib/python3.7/site-packages (from gensim==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/salatiel/anaconda3/lib/python3.7/site-packages (from gensim==3.6.0) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim==3.6.0\n",
    "#!pip install binary gensim==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_826502/44810157.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as postgres\n",
    "import psycopg2.extras\n",
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from configparser import ConfigParser\n",
    "# from sshtunnel import SSHTunnelForwarder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(filename='database.ini', section='postgresql'):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "\n",
    "    # get section, default to postgresql\n",
    "    config = {}\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "        for param in params:\n",
    "            config[param[0]] = param[1]\n",
    "    else:\n",
    "        raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n",
    "\n",
    "    return config\n",
    "def connect(config):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    try:\n",
    "        # connecting to the PostgreSQL server\n",
    "        with psycopg2.connect(**config) as conn:\n",
    "            print('Connected to the PostgreSQL server.')\n",
    "            return conn\n",
    "    except (psycopg2.DatabaseError, Exception) as error:\n",
    "        print(error)\n",
    "\n",
    "# def connect():\n",
    "#     conn = None\n",
    "#     try:\n",
    "#         conn = postgres.connect(\n",
    "#             host=\"localhost\",\n",
    "#             #database=\"nashville\",\n",
    "#             database=\"new-york_test\",\n",
    "#             user=\"salatiel\",\n",
    "#             password=\"root\",\n",
    "#             port = 5432) #8000 - LACINA PC\n",
    "#                          #5432 - LOCALHOST\n",
    "#     except postgres.Error as e:\n",
    "#         print(e)\n",
    "#     return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeConnection(conn):\n",
    "    sucess = False\n",
    "    try:\n",
    "        conn.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeQuery(conn, sql):\n",
    "    record = None\n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.RealDictCursor)\n",
    "        cur.execute(sql)\n",
    "        record = cur.fetchall()\n",
    "        cur.close()\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeInsert(conn, sql):\n",
    "    sucess = False\n",
    "            \n",
    "    try:\n",
    "        #print(sql)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        sucess = True\n",
    "    except postgres.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "\n",
    "    return sucess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recebe um id e retorna as categorias e checkin do lugar\n",
    "def getPOIInformation(conn, business_id):\n",
    "    \n",
    "    sql = \"\"\"\n",
    "        SELECT category FROM pois_information WHERE id  = \\'\"\"\"+str(business_id)+ \"\"\"\\'\n",
    "    ;\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encontra todos os pontos do bin centrado em um POI trazendo suas informações (categorias e checkin)\n",
    "def getBinPOIsInformation(conn, business_id, bin_number):\n",
    "\n",
    "    result = None\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT fk_poi_id_context, name, level, checkin_count, distance_m \n",
    "        FROM bins_pois_information \n",
    "        WHERE fk_poi_id_center = \\'\"\"\"+str(business_id)+\"\"\"\\' AND fk_bin_number = \"\"\"+str(bin_number)+\"\"\";\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que obtém as informações de uma view materializada referente ao OSM\n",
    "def getBinOSMInformation(conn, business_id, materialized_view):\n",
    "    result = None\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM \"\"\"+materialized_view+\"\"\"\n",
    "        WHERE id = \\'\"\"\"+str(business_id)+\"\"\"\\';\"\"\"\n",
    "\n",
    "    #print (sql)\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que obtém as estatísticas do BIN como contagem de POIs e soma dos Checkins\n",
    "def getBinStats(conn, business_id, binRange):\n",
    "\n",
    "    sql = \"\"\"\n",
    "    SELECT count(business_id) as quantity, sum(checkin_count) as total_checkin FROM poi WHERE business_id IN (\n",
    "        SELECT fk_poi_business_id_01 FROM has_distance WHERE distance_m >= \"\"\"+str(binRange[0])+\"\"\" AND distance_m < \"\"\"+str(binRange[1])+\"\"\"\n",
    "                                            AND fk_poi_business_id_02 = \\'\"\"\"+str(business_id)+\"\"\"\\'\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategoryInformation(data, category):\n",
    "   \n",
    "    occurences = 0\n",
    "    checkin = 0\n",
    "\n",
    "     #Formato de data\n",
    "    #[business_id, checkin, category]\n",
    "    for item in data:\n",
    "        if(item[2] == category):\n",
    "            occurences = occurences + 1\n",
    "            checkin = checkin + item[1]\n",
    "    \n",
    "    return [checkin, occurences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinArea(conn, id, bin_number):\n",
    "    sql = \"\"\"\n",
    "        SELECT ST_AREA(ST_Transform(bin.geom, 3857)) * 0.3048 ^ 2 area\n",
    "        FROM bin\n",
    "        WHERE bin.number = \"\"\"+bin_number+\"\"\" LIMIT 1; ;\n",
    "    \"\"\"\n",
    "    \n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEOC2VEC - [POI, GEO] (Todos abaixo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "def calculateBinOSMPolygon_Disco(df, mi = 10):\n",
    "    \n",
    "    weights = [0.7]\n",
    "    #radius = (1+radius)*100\n",
    "    #area = math.pi*(radius*radius)\n",
    "\n",
    "    radius = 400\n",
    "    \n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        \n",
    "    \n",
    "        file_name = './geographic/train_files/new-york-sl-tuple-geoc2vec-pois_polygons_information-pfp-c.csv'\n",
    "    \n",
    "    \n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                         \"center_poi\",\n",
    "                         \"context_osm\"])\n",
    "        \n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    try:\n",
    "\n",
    "        config = load_config()\n",
    "\n",
    "        connection = connect(config)\n",
    "\n",
    "        for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        #for id_01, poi in df.iterrows():\n",
    "            \n",
    "\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['POI_id'])\n",
    "\n",
    "            \n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['POI_id'], 'pois_polygons_information')\n",
    "            #print(bin_osm_information)\n",
    "            bin_osm_building_information = getBinOSMInformation(connection, poi['POI_id'], 'pois_polygons_building_information')\n",
    "\n",
    "\n",
    "            #Calculando os dois parâmetros abaixo\n",
    "            #oc- total de tipos diferentes de polygons no bin\n",
    "            oc = 0\n",
    "            sc = 0\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "                #Verificando quantos tipos de polygons diferentes existem\n",
    "                \n",
    "                oc = oc + bin_osm_information.iloc[:,2:len(tags)-2][~bin_osm_information.iloc[:,2:len(tags)-2].isin(['None'])].count().sum()\n",
    "                \n",
    "                sc = sc + (bin_osm_information.iloc[:,2:len(tags)-2][~bin_osm_information.iloc[:,2:len(tags)-1].isin(['None'])].count(axis=1)*bin_osm_information['way_area_m']).sum()\n",
    "                \n",
    "                #Excluindo ids e radius\n",
    "                # print(\"TAGS 1\")\n",
    "                # print(tags)\n",
    "\n",
    "                tags = tags[2:len(tags) - 2]\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_building_information) > 0):\n",
    "                tags_buildings = list(dict(bin_osm_building_information[0]).keys())\n",
    "                bin_osm_building_information = pd.DataFrame(bin_osm_building_information, columns = tags_buildings)\n",
    "\n",
    "                oc = oc + bin_osm_building_information.iloc[0]['building_count']\n",
    "                \n",
    "                sc = sc + bin_osm_building_information.iloc[0]['area_total']\n",
    "\n",
    "                #Excluindo ids e radius\n",
    "                # print(\"TAGS 2\")\n",
    "                # print(tags_buildings)\n",
    "                tags_buildings = tags_buildings[1:]\n",
    "                \n",
    "            #Para evitar divisão por zero\n",
    "            if(oc != 0):\n",
    "                if (len(bin_osm_information) > 0):\n",
    "                    for tag in tags:\n",
    "                        #Percorrer cada tag\n",
    "                        geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                        for feature in geographic_features:\n",
    "\n",
    "                            if(feature != None):\n",
    "\n",
    "                                #sf = all area o tag\n",
    "                                #op = all occurences of tag \n",
    "                                \n",
    "                                sf = bin_osm_information[bin_osm_information[tag] == feature]['way_area_m'].sum()\n",
    "                                of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "\n",
    "                                SP = math.ceil((sf/sc)*mi)        \n",
    "                                OP = math.ceil((of/oc)*mi)\n",
    "                                \n",
    "                                for idx, w in enumerate(weights):\n",
    "                                    \n",
    "\n",
    "                                    aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "\n",
    "\n",
    "                                    if (aug <= 0):\n",
    "                                        aug = 1\n",
    "\n",
    "                                    #print(tag, value)\n",
    "                                    name = \"polygons_\"+tag+\"_\"+feature\n",
    "\n",
    "                                    for center_poi in poi_information: # Para cada tki\n",
    "                                        #Aumentando-o pelo fator b\n",
    "                                        for b in range(aug):\n",
    "\n",
    "                                            line = [str(poi['POI_id']), \n",
    "                                                    str(center_poi['category']),\n",
    "                                                    str(name)]\n",
    "                                            writers[idx].writerow(line)\n",
    "\n",
    "                #Calculando a co-ocorrência com polígonos que são unicamente prédios                    \n",
    "                if (len(bin_osm_building_information) > 0):\n",
    "\n",
    "                    for id_02, row in bin_osm_building_information.iterrows(): #Possui uma linha por bin\n",
    "\n",
    "                            #sf = all area o tag\n",
    "                            #of = all occurences of tag\n",
    "\n",
    "                            sf = row['area_total']\n",
    "                            of = row['building_count']\n",
    "\n",
    "                            SP = math.ceil((sf/sc)*mi)        \n",
    "                            OP = math.ceil((of/oc)*mi)\n",
    "                            \n",
    "                            for idx, w in enumerate(weights):\n",
    "\n",
    "                                aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "                                if (aug <= 0):\n",
    "                                    aug = 1\n",
    "\n",
    "                                name = 'polygons_building_yes'\n",
    "\n",
    "                                for center_poi in poi_information: # Para cada tki\n",
    "                                    #Aumentando-o pelo fator b\n",
    "                                    for b in range(aug):\n",
    "\n",
    "                                        line = [str(poi['POI_id']), \n",
    "                                                str(center_poi['category']),\n",
    "                                                str(name)]\n",
    "                                        writers[idx].writerow(line)\n",
    "                    \n",
    "        for csv_file in csv_files:\n",
    "            csv_file.close()\n",
    "        connection.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        #print(\"Connection Failed\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "# Rodar pra roads e linas e realizar ajustes igual o codigo de cima\n",
    "def calculateBinOSMergedRoadsLines_Disco(df, mi=20, roads=True):\n",
    "    \n",
    "    radius = 400\n",
    "    # w = round(w, 1)\n",
    "    w = 0.7\n",
    "    \n",
    "    if(roads):\n",
    "        t_name = 'pois_roads_information'\n",
    "        table = \"roads\"\n",
    "        materialized_view = 'pois_roads_information'\n",
    "    else:\n",
    "        t_name = 'pois_lines_information'\n",
    "        table = \"lines\"\n",
    "        materialized_view = 'pois_lines_information'\n",
    "\n",
    "    print(\"executing radius:\", radius, \"\\tweight:\", w)\n",
    "\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './geographic/train_files/new-york-sl-tuple-geoc2vec-' + t_name + '-pfp-c.csv'\n",
    "    \n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\n",
    "                     \"center_poi\",\n",
    "                     \"context_osm\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    config = load_config()\n",
    "    connection = connect(config)  \n",
    "\n",
    "    if (connection != None):\n",
    "        \n",
    "        #centros\n",
    "        for id_01, poi in df.iterrows():\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['POI_id'])\n",
    "\n",
    "\n",
    "            #[business_id, checkin, category, distance_m]\n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['POI_id'], materialized_view)\n",
    "\n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "                #Calculando os dois parâmetros abaixo\n",
    "                #oc - total de roads/lines no bin\n",
    "                oc = bin_osm_information.iloc[:,2:len(tags)-2][~bin_osm_information.iloc[:,2:len(tags)-2].isin(['None'])].count().sum()\n",
    "                \n",
    "                #sc - comprimento total de cada tipo de roads/lines no bin\n",
    "                sc = (bin_osm_information.iloc[:,2:len(tags)-2][~bin_osm_information.iloc[:,2:len(tags)-2].isin(['None'])].count(axis=1)*bin_osm_information['length']).sum()\n",
    "\n",
    "                \n",
    "                #Excluindo ids e radius\n",
    "                # print(\"TAGS\")\n",
    "                # print(tags)\n",
    "                \n",
    "                tags = tags[2:len(tags)-2]\n",
    "            \n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "                #Para evitar divisão por zero\n",
    "                if(oc != 0):\n",
    "                    for tag in tags:\n",
    "                        #Percorrer cada tag\n",
    "                        geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                        for feature in geographic_features:\n",
    "\n",
    "                            if(feature != None):\n",
    "\n",
    "                                #sp = all length o tag\n",
    "                                #op = all occurences of tag\n",
    "                                sf = bin_osm_information[bin_osm_information[tag] == feature]['length'].sum()\n",
    "                                of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                \n",
    "                                SP = math.ceil((sf/sc)*mi)        \n",
    "                                OP = math.ceil((of/oc)*mi)\n",
    "\n",
    "                                aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "\n",
    "                                if (aug <= 0):\n",
    "                                    aug = 1\n",
    "                                \n",
    "                                name = table+\"_\"+tag+\"_\"+feature\n",
    "\n",
    "                                for center_poi in poi_information: # Para cada tki\n",
    "                                    #Aumentando-o pelo fator b\n",
    "                                    for b in range(aug):\n",
    "                                        line = [str(poi['POI_id']), \n",
    "                                                str(center_poi['category']),\n",
    "                                                str(name)]\n",
    "                                        writer.writerow(line)\n",
    "\n",
    "                                \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "# TODO ajustar\n",
    "\n",
    "def calculateBinOSMPoints_Disco(df, mi=20):\n",
    "    \n",
    "    radius = 400\n",
    "    print(\"executing radius:\", radius)\n",
    "\n",
    "    #Arquivo para salvar diretamente no disco\n",
    "    file_name = './geographic/train_files/new-york-sl-tuple-geoc2vec-pois_points_information-pfp-c.csv'\n",
    "    \n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\n",
    "                     \"center_poi\",\n",
    "                     \"context_osm\"])\n",
    "\n",
    "    #Criando canal de comunicação com a base de dados\n",
    "    config = load_config()\n",
    "    connection = connect(config)  \n",
    "\n",
    "    if (connection != None):\n",
    "\n",
    "        for id_01, poi in df.iterrows():\n",
    "            #print('calculating point:', id_01, 'id:', poi['business_id'])\n",
    "\n",
    "            #[business_id, checkin, category]\n",
    "            poi_information = getPOIInformation(connection, poi['POI_id'])\n",
    "\n",
    "\n",
    "            #[POI_id, checkin, category, distance_m]\n",
    "            \n",
    "            bin_osm_information = getBinOSMInformation(connection, poi['POI_id'], 'pois_points_information')\n",
    "\n",
    "            \n",
    "            #Se o bin está preenchido com alguma informação\n",
    "            if (len(bin_osm_information) > 0):\n",
    "\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "            \n",
    "                #oc - total de tipos diferentes de points no bin\n",
    "                oc = bin_osm_information.iloc[:,2:len(tags)-1][~bin_osm_information.iloc[:,2:len(tags)-1].isin(['None'])].count().sum()\n",
    "                \n",
    "                #Excluindo ids e radius\n",
    "                tags = tags[2:len(tags)-1]\n",
    "                \n",
    "                #As adições são feitas baseadas nos rótulos\n",
    "\n",
    "                #Para evitar divisão por zero\n",
    "                if(oc != 0):\n",
    "\n",
    "                    for tag in tags:\n",
    "                        #Percorrer cada tag\n",
    "                        geographic_features = set(bin_osm_information[tag].values)\n",
    "                        \n",
    "                        for feature in geographic_features:\n",
    "                            \n",
    "                            if(feature != None):\n",
    "                                \n",
    "                                of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                \n",
    "                                OP = (of/oc)*mi\n",
    "                                \n",
    "                                aug = math.ceil(OP)\n",
    "                                if (aug <= 0):\n",
    "                                    aug = 1\n",
    "                                \n",
    "                                name = \"points_\"+tag+\"_\"+feature\n",
    "\n",
    "\n",
    "                                for center_poi in poi_information: # Para cada tki\n",
    "                                    #Aumentando-o pelo fator b\n",
    "                                    for b in range(aug):\n",
    "\n",
    "                                        line = [str(poi['POI_id']), \n",
    "                                                str(center_poi['category']),\n",
    "                                                str(name)]\n",
    "                                        writer.writerow(line)\n",
    "        \n",
    "            #break\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração do ITDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5099, 4)\n",
      "(5099, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POI_id</th>\n",
       "      <th>POI_catname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49bbd6c0f964a520f4531fe3</td>\n",
       "      <td>Arts &amp; Crafts Store</td>\n",
       "      <td>40.719810</td>\n",
       "      <td>-74.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a43c0aef964a520c6a61fe3</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>40.606800</td>\n",
       "      <td>-74.044170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4c5cc7b485a1e21e00d35711</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>40.716162</td>\n",
       "      <td>-73.883070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce1863bc4f6a35d8bd2db6c</td>\n",
       "      <td>Home (private)</td>\n",
       "      <td>40.619151</td>\n",
       "      <td>-74.035888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c0ab56f7e3fc9288c1df482</td>\n",
       "      <td>Mobile Phone Shop</td>\n",
       "      <td>40.741191</td>\n",
       "      <td>-73.989663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     POI_id          POI_catname   latitude  longitude\n",
       "0  49bbd6c0f964a520f4531fe3  Arts & Crafts Store  40.719810 -74.002581\n",
       "1  4a43c0aef964a520c6a61fe3               Bridge  40.606800 -74.044170\n",
       "2  4c5cc7b485a1e21e00d35711       Home (private)  40.716162 -73.883070\n",
       "3  4ce1863bc4f6a35d8bd2db6c       Home (private)  40.619151 -74.035888\n",
       "4  4c0ab56f7e3fc9288c1df482    Mobile Phone Shop  40.741191 -73.989663"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de tuplas de vizinhos nos dados do yelp (center, context) considerando d = 100m\n",
    "pois_file_name = '../dataset/NYC/original/all_pois.csv'\n",
    "#pois_file_name = './nashville-ml-updated.csv'\n",
    "#pois_file_name = './valid_pois.csv'\n",
    "df = pd.read_csv(pois_file_name)\n",
    "df.drop(columns=[\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteractive Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 400 m\n",
      "Connected to the PostgreSQL server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5099/5099 [01:13<00:00, 69.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calculateBinOSMPolygon_Disco(df, mi=5)\n",
    "\n",
    "# Rodar duas vezes\n",
    "# calculateBinOSMergedRoadsLines_Disco(df, mi=20, roads=True)\n",
    "# calculateBinOSMergedRoadsLines_Disco(df, mi=20, roads=False)\n",
    "\n",
    "# calculateBinOSMPoints_Disco(df, mi=20)\n",
    "#calculateSharedContextByType_disco(n)\n",
    "#calculateBinOSM_Disco(df, n, 'bins_points_information', 0.5)\n",
    "#calculateBinOSM_Disco(df, n, 'bins_lines_information', 0.5)\n",
    "#calculateBinOSM_Disco(df, n, 'bins_roads_information', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 400 \tweight: 0.7\n",
      "Connected to the PostgreSQL server.\n"
     ]
    }
   ],
   "source": [
    "# Roads True\n",
    "calculateBinOSMergedRoadsLines_Disco(df, mi=5, roads=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 400 \tweight: 0.7\n",
      "Connected to the PostgreSQL server.\n"
     ]
    }
   ],
   "source": [
    "# Roads False\n",
    "calculateBinOSMergedRoadsLines_Disco(df, mi=5, roads=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 400\n",
      "Connected to the PostgreSQL server.\n"
     ]
    }
   ],
   "source": [
    "calculateBinOSMPoints_Disco(df, mi=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITDL em Paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-10T21:50:03.236761Z",
     "iopub.status.busy": "2021-08-10T21:50:03.236417Z",
     "iopub.status.idle": "2021-08-10T23:51:59.673123Z",
     "shell.execute_reply": "2021-08-10T23:51:59.671871Z",
     "shell.execute_reply.started": "2021-08-10T21:50:03.236732Z"
    }
   },
   "outputs": [],
   "source": [
    "# import multiprocessing as mp\n",
    "# print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# # Step 1: Init multiprocessing.Pool()\n",
    "# pool = mp.Pool(int(mp.cpu_count()/2))\n",
    "\n",
    "# # Step 2: `pool.apply` the `howmany_within_range()`\n",
    "# bins = range(0, 4)\n",
    "# #bins = [0]\n",
    "# #[pool.apply(calculateBin, args=(df, n, 100, 0.3)) for n in bins]\n",
    "# pool.starmap(calculateBin, [(df, n, 100, 0.7) for n in bins])\n",
    "\n",
    "# # Step 3: Don't forget to close\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  20\n",
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [17:39<00:00, 21.14it/s]\n",
      "100%|██████████| 22399/22399 [20:21<00:00, 18.34it/s]\n",
      "100%|██████████| 22399/22399 [22:15<00:00, 16.77it/s]\n",
      "100%|██████████| 22399/22399 [23:42<00:00, 15.74it/s]\n",
      "100%|██████████| 22399/22399 [24:59<00:00, 14.94it/s]\n",
      "100%|██████████| 22399/22399 [26:17<00:00, 14.20it/s]\n",
      "100%|██████████| 22399/22399 [27:32<00:00, 13.56it/s]\n",
      "100%|██████████| 22399/22399 [28:47<00:00, 12.97it/s]\n",
      "100%|██████████| 22399/22399 [30:12<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 100 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 200 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [10:06<00:00, 36.91it/s]\n",
      "100%|██████████| 22399/22399 [14:39<00:00, 25.48it/s]\n",
      " 82%|████████▏ | 18399/22399 [16:42<03:43, 17.86it/s]\n",
      "100%|██████████| 22399/22399 [18:13<00:00, 20.47it/s]\n",
      "100%|██████████| 22399/22399 [19:08<00:00, 19.50it/s]\n",
      "100%|██████████| 22399/22399 [19:49<00:00, 18.84it/s]\n",
      "100%|██████████| 22399/22399 [20:19<00:00, 18.37it/s]\n",
      "100%|██████████| 22399/22399 [20:44<00:00, 18.00it/s]\n",
      "100%|██████████| 22399/22399 [21:04<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [22:29<00:00, 16.59it/s] \n",
      "100%|██████████| 22399/22399 [24:24<00:00, 15.30it/s]\n",
      "100%|██████████| 22399/22399 [26:12<00:00, 14.25it/s]\n",
      "100%|██████████| 22399/22399 [27:58<00:00, 13.34it/s]\n",
      "100%|██████████| 22399/22399 [29:40<00:00, 12.58it/s]\n",
      "100%|██████████| 22399/22399 [31:36<00:00, 11.81it/s]\n",
      "100%|██████████| 22399/22399 [33:35<00:00, 11.11it/s]\n",
      "100%|██████████| 22399/22399 [35:46<00:00, 10.44it/s]\n",
      "100%|██████████| 22399/22399 [37:55<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 100\n",
      "executing radius: 200\n",
      "executing radius: 300\n",
      "executing radius: 400\n",
      "executing radius: 500\n",
      "executing radius: 600\n",
      "executing radius: 700\n",
      "executing radius: 800\n",
      "executing radius: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [09:59<00:00, 37.37it/s]\n",
      "100%|██████████| 22399/22399 [16:30<00:00, 22.61it/s]\n",
      " 85%|████████▍ | 19001/22399 [17:55<03:08, 18.06it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 22399/22399 [20:13<00:00, 18.46it/s]\n",
      "100%|██████████| 22399/22399 [21:07<00:00, 17.67it/s]\n",
      "100%|██████████| 22399/22399 [21:54<00:00, 17.04it/s]\n",
      "100%|██████████| 22399/22399 [22:44<00:00, 16.41it/s]\n",
      "100%|██████████| 22399/22399 [23:29<00:00, 15.89it/s]\n",
      "100%|██████████| 22399/22399 [24:21<00:00, 15.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "#pool = mp.Pool(int(mp.cpu_count()-4))\n",
    "#pool = mp.Pool(int(mp.cpu_count()))\n",
    "pool = mp.Pool(11)\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "#weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "#weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "#n = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "mi = 20\n",
    "\n",
    "pool.starmap(calculateBinOSMPolygon_dst_Disco, [(df, n,  mi) for n in bins])\n",
    "#pool.starmap(calculateBinOSMRoadsLinesM_Disco, [(df, n, w) for w in weights])\n",
    "pool.starmap(calculateBinOSMRoadsLines_dst_Disco, [(df, n,  mi, True) for n in bins])\n",
    "pool.starmap(calculateBinOSMRoadsLines_dst_Disco, [(df, n,  mi, False) for n in bins])\n",
    "pool.starmap(calculateBinOSMPoints_dst_Disco, [(df, n,  mi) for n in bins])\n",
    "\n",
    "\n",
    "#LEMBRE DE EXECUTAR AO CONTRÁRIO\n",
    "\n",
    "#pool.starmap(calculateBin_Disco, [(df, n, w) for w in weights])\n",
    "#pool.starmap(calculateGUBin_Disco, [(df, n,  w) for w in weights])\n",
    "#pool.starmap(calculateCGBin_Disco, [(df, n,  w) for w in weights])\n",
    "#pool.starmap(calculateCGUBin_Disco, [(df, n, 'geographic', w) for w in weights])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()\n",
    "\n",
    "#Para point\n",
    "#calculateBinOSMPoints_Disco(df, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  20\n",
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [09:38<00:00, 38.70it/s]\n",
      "100%|██████████| 22399/22399 [14:02<00:00, 26.60it/s]\n",
      "100%|██████████| 22399/22399 [15:56<00:00, 23.41it/s]\n",
      "100%|██████████| 22399/22399 [17:23<00:00, 21.46it/s]\n",
      "100%|██████████| 22399/22399 [18:15<00:00, 20.45it/s]\n",
      "100%|██████████| 22399/22399 [18:48<00:00, 19.86it/s]\n",
      "100%|██████████| 22399/22399 [19:18<00:00, 19.34it/s]\n",
      "100%|██████████| 22399/22399 [19:39<00:00, 19.00it/s]\n",
      "100%|██████████| 22399/22399 [19:55<00:00, 18.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [20:51<00:00, 17.90it/s]\n",
      "100%|██████████| 22399/22399 [22:08<00:00, 16.85it/s]\n",
      "100%|██████████| 22399/22399 [23:28<00:00, 15.90it/s]\n",
      "100%|██████████| 22399/22399 [24:50<00:00, 15.03it/s]\n",
      "100%|██████████| 22399/22399 [26:11<00:00, 14.26it/s]\n",
      "100%|██████████| 22399/22399 [27:30<00:00, 13.57it/s]\n",
      "100%|██████████| 22399/22399 [29:06<00:00, 12.83it/s]\n",
      "100%|██████████| 22399/22399 [30:43<00:00, 12.15it/s]\n",
      "100%|██████████| 22399/22399 [32:31<00:00, 11.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(11)\n",
    "\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "mi = 20\n",
    "pool.starmap(calculateBinOSMRoadsLines_Estimated_Disco, [(df, n,  mi, True) for n in bins])\n",
    "pool.starmap(calculateBinOSMRoadsLines_Estimated_Disco, [(df, n,  mi, False) for n in bins])\n",
    "\n",
    "#LEMBRE DE EXECUTAR AO CONTRÁRIO\n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abordagem Nayve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  16\n",
      "executing bin: 5\n",
      "executing bin: 6\n",
      "executing bin: 7\n",
      "executing bin: 8\n",
      "executing bin: 5\n",
      "executing bin: 6\n",
      "executing bin: 7\n",
      "executing bin: 8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(4)\n",
    "#pool = mp.Pool(int(mp.cpu_count()))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "bins = range(0, 9)\n",
    "\n",
    "pool.starmap(calculateNayveBinOSMPolygon_Disco, [(df, n) for n in bins])\n",
    "pool.starmap(calculateNayveBinOSMRoadsLines_Disco, [(df, n, True) for n in bins])\n",
    "pool.starmap(calculateNayveBinOSMRoadsLines_Disco, [(df, n, False) for n in bins])\n",
    "pool.starmap(calculateNayveBinOSMPoints_Disco , [(df, n) for n in bins])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateBinOSMPoints_Disco(df, 0)\n",
    "#calculateBinOSMRoadsLines_Disco(df, 0, True)\n",
    "#calculateBinOSMRoadsLines_Disco(df, 0, False)\n",
    "#calculateBinOSMPolygon_Disco(df, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a, bin_number):\n",
    "    print(bin_number)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i) for i in bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  20\n",
      "6\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(int(mp.cpu_count()))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "bins = [0, 1, 2, 3, 4, 5, 6]\n",
    "a = 2\n",
    "\n",
    "pool.starmap(test, [(a, i) for i in bins])\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c960ebc558cb47a91b30b6a69e09ee33d8511507a0164b187e789d12f3a22a9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
